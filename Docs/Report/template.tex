\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{ifpdf,newtxtext,newtxmath} 
\usepackage{array,graphicx,dcolumn,multirow,hevea,abstract,hanging,fancyhdr}
% change next 3 lines each issue
\newcommand{\jhead}{Advanced Network Management 2020}
\topmargin=-.3in \oddsidemargin=.3in \evensidemargin=.3in \textheight=9in \textwidth=6in
\pagestyle{fancy} 
\fancyhead[L]{\protect\small \href{\jref}{\jhead}\jdate}
\fancyhead[R]{\protect\small Assignment 3 - Group project} % replace with running head
\fancypagestyle{first-page}{%
 \lhead{\protect\small \href{\jref}{\jhead}}
 \rhead{}
}
\usepackage[labelfont=sc,textfont=sf]{caption}
\usepackage[hyperfootnotes=false,breaklinks=true]{hyperref} 
\urlstyle{rm}
\usepackage[hyphenbreaks]{breakurl}
\usepackage{booktabs}
\newcolumntype{L}[1]{>{\raggedright\arraybackslash }p{#1}}
\newcolumntype{C}[1]{>{\centering\arraybackslash }p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\arraybackslash }p{#1}}
\newcolumntype{d}[1]{D{.}{.}{#1}}
\newcommand{\mc}{\multicolumn}
\setlength\tabcolsep{1mm}
\setlength\columnsep{5mm}
\setlength\abovecaptionskip{1ex}
\setlength\belowcaptionskip{.5ex}
\setlength\belowbottomsep{.3ex}
\setlength\lightrulewidth{.04em}
\renewcommand\arraystretch{1.2}
\renewcommand{\topfraction}{1}
\renewcommand{\textfraction}{0}
\renewcommand{\floatpagefraction}{.9}
\widowpenalty=1000
\clubpenalty=1000
\setlength{\parskip}{0ex}
\let\tempone\itemize
\let\temptwo\enditemize
\let\tempthree\enumerate
\let\tempfour\endenumerate
\renewenvironment{itemize}{\tempone\setlength{\itemsep}{0pt}}{\temptwo}
\renewenvironment{enumerate}{\tempthree\setlength{\itemsep}{0pt}}{\tempfour}

\setcounter{page}{1} 

\title{Micro-Service System Troubleshooting}

\author{
Henry Zheng
\and 
Sahand Sabour
\and
Samuel Pegg
}

\date{} % leave empty
\begin{document}

\begin{htmlonly}
\href{\jref}{\jhead}, \jdate, pp.\
\end{htmlonly}

\maketitle
\thispagestyle{first-page}

\begin{abstract}
\noindent With the rapid growth of large micro-service based systems, detecting anomalies in system operations has become a significantly essential task. In addition, the root causes of such anomalies must also be detected to prevent major costs and losses. Due to the large number of existing calls and complex relationships between different micro-services in modern systems, manual inspection of such micro-services has become extremely challenging and rather impossible. Hence, developing a set of methods that accomplish these tasks within a timely manner and with high accuracy is highly necessary. In this report, we propose an online algorithm that analyzes data generated from a micro-service based system and detects the occurring anomalies and their corresponding root causes. 

\smallskip
\noindent
Keywords: micro-service, anomaly detection, root cause analysis, root cause detection
\end{abstract}


\section{Introduction}
With the recent trends, increasing number of modern day large-scale systems are utilizing micro-services in their system architecture design. In a micro-service based architecture, the system operations are provided as different services, which are loosely coupled (i.e. independent from each other), organized, and highly maintainable, analyzable, and testable. Hence, this type of architecture allows large-scale and complex systems to provide faster and more reliable services to their users. However, a major disadvantage of these systems is the massive number of calls between different services and their complex relationships; which in turn makes finding faulty services and errors rather challenging.

\noindent In the case that a faulty micro-service causes an error in the system, this occurrence would be referred to as an anomaly, which should be detected as soon as possible. Accordingly, the anomaly should be traced back to the faulty service that caused it. This process is referred to as troubleshooting and by accomplishing this task, the system maintainers would be able to fix the faulty service and any subsequent problems before experiencing major costs and losses. Therefore, implementing an algorithm that detects system's anomalous behavior and is able to both accurately and efficiently identify its root cause is essential.

\noindent In this project, we were tasked to design an online algorithm to perform these tasks on an incrementally published dataset (i.e. real-time data) generated by a micro-service based system through Kafka producer. More specifically, our task was to analyze the provided time series data, detect anomalous behavior, discover anomalous system nodes at the time of this occurrence, and find the Key Performance Indicator (KPI) that is the root cause of this anomaly. The rest of this report is organized as follows: in section 2, we summarize the relative literature for these tasks and acknowledge the work of top teams for this competition; in section 3, we further explain the problem statement and provide our implemented algorithms for this project; section 4 includes a discussion of our results as well as the lessons learned; lastly, we conclude the report in section 5. 
\section{Related Work}
As mentioned, micro-service based large-scale systems consists of large number of complex calls and relationships between different services. In addition, once a service in the system becomes unavailable, unstable, and/or impaired, detecting and fixing this system in a timely and accurate manner is the top priority. Due to the large amount of data to be analyzed, manual inspection has proven to be hugely time consuming and overall, an ineffective approach. Hence, considerable research has been conducted to automatically analyze and detect such failures and their causing factors.\\
For the task of anomaly detection, the problem statement would be fairly simple: given the history of seasonal KPI data from a micro-service based system, create a time series and detect the present outliers. Donut [1] and Bagel [2] managed to accomplish this task by utilizing variational auto-encoders (VAEs). However, these models achieve satisfactory results for this task; however, they need sufficient resources for training and given that we were not provided with any GPUs, they were not suitable for our project. In addition, TraceAnomaly [3], a deep Bayesian network based algorithm, also managed to obtain accurate results within a short duration. However, given that it is a deep learning algorithm, similar to the previous two approaches, it was not suitable for our project. \\
For our method, we drew huge inspiration from MicroRCA [4] as the proposed framework and their studied cases strongly resembled this competition. Their approach would first detect anomalies in the time series data using BIRCH [5]. As will be mentioned later in section 3, we also used this algorithm for anomaly detection in the first part of our approach. Accordingly, an attributed graph between the hosts and services are created and the sub-graph corresponding to the detected anomaly is extracted. Lastly, the edges and nodes of the extracted sub-graph are weighted using Pearson's correlation function, and the faulty services are localized by utilizing Personalized PageRank [6]. We implemented different variations of weighting and PageRank but were unable to produce satisfactory results. \\
Regarding the proposed algorithms for this competition, the winning team [7] cleverly discarded one of the three provided data sources to increase the detection speed. Accordingly, they established a set of rules and manually selected thresholds to detect anomalies and localize root causes. Similarly, the runner up team [8] also discarded the first set of provided KPI sources, focused merely on trace data and formulated this problem as a pattern finding challenge in a constructed anomaly table. Lastly, the team in third place [3] utilized the first set of available data to identify the anomalous points, analyzed the second set to detect failed and delayed calls, find abnormal hosts, and extract the necessary features. One of the honorable mentions in their work was that they used dictionaries instead of pandas to improve the algorithm's speed. 
\section{Methodology} 
In this section, we describe the problem statement and our implemented algorithms.

\vspace{-0.2cm}
\subsection{Problem Statement}
In this project, we were provided with three KPI data sources: ESB, Trace, and Host data.

\smallskip\smallskip
\noindent \textbf{ESB business indicator (ESB): }it is provided every minute and mainly demonstrates the number of requests for the \textit{osb\_001} service and the overall success rate of these request during each minute. Once an anomaly occurs, assuming at a point t in time, the success rate is expected to be lower than 1. Accordingly, t would be recorded to be used for further analysis in the other two KPI data sources.

\smallskip
\noindent \textbf{Trace: }it is provided for every request and consists of several micro-service calls, referred to as spans. This section of the data demonstrates the start and elapsed time for each span, the databases that were accessed (if any), the trace of the span and its host. Upon finding anomalous time t in the ESB data, the time around t is to be investigated in order to detect anomalous spans (i.e. nodes with unusually long response time) and ultimately, realize faulty service nodes. 

\smallskip
\noindent \textbf{Host: }are provided in the (timestamp, value) format and includes the host service name and the called operation. Upon finding the faulty service nodes, this data can be explored to find anomalous values for a KPI, which would then be flagged as a root cause.

\vspace{-0.2cm}
\subsection{Proposed Method}
Similar to the previous section, our proposed method consists of three parts corresponding to the three different KPI data sources that we are provided: ESB, Trace, and Host analysis.

\smallskip\smallskip
\noindent \textbf{ESB business indicator (ESB): }Inspired by [2], we utilize BIRCH [3], which is an online clustering-based outlier detection algorithm, to detect anomalies in the ESB data. In this project, we consider comparatively large values for average time and considerably small success rates as anomalous behavior. Hence, we employed BIRCH separately for these two columns and set the BIRCH threshold (i.e. radius) to 0.5 and 0.1 respectively. \\ The algorithm produced satisfactory results; however, a major disadvantage of this implementation was that the anomaly detection process was bound to be started when the system is in its normal state. Otherwise, the anomaly would be flagged as the normal state of the system and all the proceeding values would be considered as anomalies. In order to address this problem, we pretrained two separate BIRCH models for average time and success rate respectively on the provided two weeks of data. \\
Upon detecting an anomaly in the ESB data, we would stop analyzing incoming data until a root cause is found. Accordingly, we would send the timestamp of the detected anomaly to the next module for faulty service detection in trace data. The incoming data would not be discarded but rather stored in a separate storage for future analysis.
\\
\smallskip\smallskip
\noindent \textbf{Trace: }
\\
\smallskip\smallskip
\noindent \textbf{Host: }
\\
\section{Discussion and Lessons Learned}
In the final test of this competition, we were able to score 70 points and rank $8^{th}$. After finishing this competition and analyzing the proposed algorithms of the top teams, we believe that we learned a number of valuable lessons throughout this experience: first, in anomaly detection, data processing is the most important step of the method and should not be undermined. With efficient data processing, the important features of the available data, which is highly beneficial for the proceeding steps of the algorithm, could be extracted; second, during this competition, we had the opportunity to work with seasonal data and different deep learning algorithms and approaches, which served as a great learning experience; third, judging by the methods that scored the most points, we learned that over complicating the problem is not a good idea and we should always try to make easy solutions work first; last, the most valuable lesson of all for us was to always make sure that all parts of the program are able to work as expected. For instance, in the final days of testing, we forgot to uncomment the submit function, which resulted in our team to score 0 points regardless of our improvements in the code. Hence, to conclude, the overall lesson would be to never take parts of your work for granted and ensure all parts are working as planned, try the simple approaches first, and learn as you work. 
\section{Conclusion}
In conclusion, we proposed a rather robust online algorithm for anomaly detection and root cause localization in micro-service based systems. We introduced the related work in the literature and the proposed method of fellow competitors. In addition, we demonstrated our proposed methodology and discussed the lessons learned throughout this project. Regardless of the final results, we regard this competition as a valuable learning experience and are proud of our team's hard work to obtain these results. 
\section*{References}
\begin{hangparas}{1em}{1}
[1] Haowen Xu,  Wenxiao  Chen, Nengwen Zhao,  Zeyan  Li, Jiahao  Bu, Zhihan  Li,  Ying Liu,  Youjian Zhao,Dan  Pei, Yang Feng. "Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications". Proceedings of the 2018 World Wide Web Conference on World Wide Web, 2018, pp. 187-196.

\smallskip\smallskip
[2] Zeyan Li, Wenxiao Chen, Dan Pei. "Robust and Unsupervised KPI Anomaly Detection Based on Conditional Variational Autoencoder". 2018 IEEE 37th International Performance Computing and Communications Conference (IPCCC). IEEE, 2018.

\smallskip\smallskip
[3] Ping Liu, Haowen Xu, Qianyu Ouyang, Rui Jiao, Zhekang Chen, Shenglin Zhang, Jiahai Yang, Linlin Mo, Jice Zeng, Wenman Xue, Dan Pei. "Unsupervised Detection of Microservice Trace Anomalies through Service-Level Deep Bayesian Networks". 31th International Symposium on Software Reliability Engineering (ISSRE). IEEE, 2020.


[4] Li Wu, Johan Tordsson, Erik Elmroth, Odej Kao. "MicroRCA: Root Cause Localization of Performance Issues in Microservices". IEEE/IFIP Network Operations and Management Symposium (NOMS), 2020. 

\smallskip\smallskip
[5] A. Gulenko, F. Schmidt, A. Acker, M. Wallschlager, O. Kao, and F. Liu, “Detecting anomalous behavior of black-box services modeled with distance-based online clustering”, in 2018 IEEE 11th International Conference on Cloud Computing (CLOUD), 2018.

\smallskip\smallskip
[6] G. Jeh and J. Widom, “Scaling personalized web search”, in WWW-2003, pp. 271–279.

\smallskip\smallskip
[7] Yunfeng Zhao, Xuanrun Wang, Guojie Fan. "Advanced network management - the Old Driver on Xuetang Road", 2020. 

\smallskip\smallskip
[8] Yixiong Ji, Yunpeng Liu. "Anomaly Detection and Root Cause Localization in Microservice System - meow meow group", 2020.

\smallskip\smallskip
[9] Zhangzi Hao, Yaoyu Zhang, Shaohuai Liu. "ANM project - Veritaserum", 2020. 

\vfill % use this for column breaks
\break

\end{hangparas}

\end{document}
